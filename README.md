# SentimentSense - Sentiment Analysis Service

A high-performance sentiment classification service powered by HuggingFace models, providing RESTful APIs with FastAPI, supporting Docker containerization and Kubernetes orchestration.

## ğŸŒ Live Demo

**API deployed on GKE, ready to use:**

- ğŸ”— **Base API URL**: http://34.58.0.33
- ğŸ“– **Interactive API Docs**: http://34.58.0.33/docs
- â¤ï¸ **Health Check**: http://34.58.0.33/health/simple
- ğŸ§ª **Sentiment Analysis**: http://34.58.0.33/analyze

## âœ¨ Features

- ğŸš€ **High-Accuracy Sentiment Analysis**: Powered by HuggingFace `cardiffnlp/twitter-roberta-base-sentiment-latest` model
- ğŸ“¡ **RESTful API**: FastAPI provides high-performance async interface with batch processing support
- ğŸ³ **Containerized Deployment**: Docker images supporting multi-platform deployment
- â˜¸ï¸ **Kubernetes Native**: Complete K8s configuration with auto-scaling capabilities
- â˜ï¸ **Cloud Native**: Deployed on GKE with load balancing and high availability
- ğŸ“Š **Comprehensive Monitoring**: Health checks, Prometheus metrics, Grafana dashboards
- ğŸ”„ **CI/CD Pipeline**: GitHub Actions automated testing and deployment
- ğŸ’° **Cost Optimized**: Preemptible instances, ~$110/month

## ğŸ› ï¸ Tech Stack

- **Backend**: Python 3.11 + FastAPI + Uvicorn
- **ML Model**: HuggingFace Transformers + PyTorch
- **Containerization**: Docker + Docker Compose
- **Orchestration**: Kubernetes + Helm
- **Cloud Platform**: Google Cloud Platform (GKE)
- **Monitoring**: Prometheus + Grafana
- **CI/CD**: GitHub Actions
- **Load Balancing**: GCP Load Balancer

## Project Structure

```
SentimentSense/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI application main file
â”‚   â”œâ”€â”€ models.py            # Pydantic data models
â”‚   â”œâ”€â”€ sentiment.py         # Sentiment analysis core logic
â”‚   â””â”€â”€ config.py            # Configuration management
â”œâ”€â”€ k8s/
â”‚   â”œâ”€â”€ deployment.yaml      # Kubernetes deployment configuration
â”‚   â”œâ”€â”€ service.yaml         # Kubernetes service configuration
â”‚   â””â”€â”€ ingress.yaml         # Kubernetes ingress configuration
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ deploy.sh            # Deployment scripts
â”‚   â””â”€â”€ test_api.py          # API testing scripts
â”œâ”€â”€ Dockerfile               # Docker image build file
â”œâ”€â”€ docker-compose.yml       # Docker Compose configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md               # Project documentation
```

## Quick Start

### Local Development

1. Install dependencies:
```bash
pip install -r requirements.txt
```

2. Start the service:
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

3. Access API documentation:
http://localhost:8000/docs

### Docker Deployment

```bash
# Build image
docker build -t sentiment-sense .

# Run container
docker run -p 8000:8000 sentiment-sense
```

### Kubernetes Deployment

```bash
# Apply configurations
kubectl apply -f k8s/

# Check status
kubectl get pods,svc
```

## API Usage Examples

### ğŸ§ª Online Testing (Using Deployed API)

#### Single Text Analysis

```bash
curl -X POST "http://34.58.0.33/analyze" \
     -H "Content-Type: application/json" \
     -d '{"text": "I love this product!"}'
```

#### Local Testing

```bash
curl -X POST "http://localhost:8000/analyze" \
     -H "Content-Type: application/json" \
     -d '{"text": "I love this product!"}'
```

Response:
```json
{
  "text": "I love this product!",
  "sentiment": "POSITIVE",
  "confidence": 0.9998,
  "processing_time": 0.045
}
```

### Batch Text Analysis

#### Online Testing
```bash
curl -X POST "http://34.58.0.33/analyze/batch" \
     -H "Content-Type: application/json" \
     -d '{"texts": ["I love this!", "This is terrible."]}'
```

#### Local Testing
```bash
curl -X POST "http://localhost:8000/analyze/batch" \
     -H "Content-Type: application/json" \
     -d '{"texts": ["I love this!", "This is terrible."]}'
```

## ğŸš€ One-Click GKE Deployment

### Quick Deployment (Recommended)
```bash
# One-click deployment to GKE (~$110/month)
./scripts/deploy-gke-complete.sh
```

### Ultra-Cheap Deployment
```bash
# Ultra-cheap version (~$100/month)
./scripts/deploy-toy-project.sh
```

### Cleanup Resources
```bash
# Delete all resources, stop billing
./scripts/cleanup-gke.sh
```

### Detailed Documentation
- ğŸ“‹ [Complete Deployment Guide](docs/GKE_Deployment_Guide.md)
- âš¡ [GitHub Actions CI/CD](docs/GitHub_Actions_Setup.md)
- ğŸ¯ [5-Minute Quick Start](docs/GitHub_Actions_QuickStart.md)

## ğŸ§ª Quick Testing

### Method 1: Browser Testing
Visit **http://34.58.0.33/docs** directly to use the interactive API documentation

### Method 2: Command Line Testing
```bash
# Health check
curl http://34.58.0.33/health/simple

# Sentiment analysis test
curl -X POST "http://34.58.0.33/analyze" \
     -H "Content-Type: application/json" \
     -d '{"text": "I absolutely love this amazing product!"}'

# Batch testing
curl -X POST "http://34.58.0.33/analyze/batch" \
     -H "Content-Type: application/json" \
     -d '{"texts": ["Great service!", "Terrible experience", "It is okay"]}'
```

### Expected Response
```json
{
  "text": "I absolutely love this amazing product!",
  "sentiment": "POSITIVE",
  "confidence": 0.9998,
  "processing_time": 0.045
}
```

## ğŸ“ˆ Performance Metrics

- **Response Time**: < 100ms (single text)
- **Throughput**: ~100 requests/second
- **Accuracy**: > 90% (based on RoBERTa model)
- **Availability**: 99.9% (multi-replica + auto-restart)

## ğŸ¤ Contributing

Issues and Pull Requests are welcome!

## ğŸ“„ License

MIT License
